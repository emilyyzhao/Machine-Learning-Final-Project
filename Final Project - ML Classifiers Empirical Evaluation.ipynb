{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Draw heatmaps for result of grid search and find \n",
    "#    best C for validation set.\n",
    "\n",
    "def draw_heatmap_linear(acc, acc_desc, C_list):\n",
    "    plt.figure(figsize = (2,4))\n",
    "    ax = sns.heatmap(acc, annot=True, fmt='.3f', yticklabels=C_list, xticklabels=[])\n",
    "    ax.collections[0].colorbar.set_label(\"accuracy\")\n",
    "    ax.set(ylabel='$C$')\n",
    "    plt.title(acc_desc + ' w.r.t $C$')\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heatmap_RF(acc, acc_desc, D_list):\n",
    "    plt.figure(figsize = (2,4))\n",
    "    ax = sns.heatmap(acc, annot=True, fmt='.3f', yticklabels=D_list, xticklabels=[])\n",
    "    ax.collections[0].colorbar.set_label(\"accuracy\")\n",
    "    ax.set(ylabel='$D$')\n",
    "    plt.title(acc_desc + ' w.r.t $D$')\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLogisticRegression(X_train,Y_train,X_test,Y_test):\n",
    "    C_list = [10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1] # Different C to try.\n",
    "    params = {'C': C_list}\n",
    "    grid_search = GridSearchCV(LogisticRegression(), params, cv=3, return_train_score = 'true', n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    train_acc = (grid_search.cv_results_['mean_train_score']).reshape(-1,1)\n",
    "    draw_heatmap_linear(train_acc, 'train accuracy', C_list)\n",
    "\n",
    "    val_acc = (grid_search.cv_results_['mean_test_score']).reshape(-1,1)\n",
    "    draw_heatmap_linear(val_acc, 'val accuracy', C_list)\n",
    "\n",
    "    new_classifier = LogisticRegression(C = grid_search.best_params_['C'])\n",
    "    new_classifier.fit(X_train, Y_train)\n",
    "    #test_acc = f1_score(new_classifier.predict(X_test), Y_test)\n",
    "    test_acc = new_classifier.score(X_test, Y_test)\n",
    "\n",
    "    return test_acc, grid_search.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSVMlinear(X_train,Y_train,X_test,Y_test):\n",
    "    #setup SVM\n",
    "    SVM_classifier = svm.SVC(kernel = 'linear')\n",
    "    C_list = [10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1] # Different C to try.\n",
    "    params = {'C': C_list}\n",
    "    grid_search = GridSearchCV(SVM_classifier, params, cv=3, return_train_score = 'true', n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    train_acc = (grid_search.cv_results_['mean_train_score']).reshape(-1,1)\n",
    "    draw_heatmap_linear(train_acc, 'train accuracy', C_list)\n",
    "\n",
    "    val_acc = (grid_search.cv_results_['mean_test_score']).reshape(-1,1)\n",
    "    draw_heatmap_linear(val_acc, 'val accuracy', C_list)\n",
    "\n",
    "    new_classifier = svm.SVC(kernel = 'linear', C = grid_search.best_params_['C'])\n",
    "    new_classifier.fit(X_train, Y_train)\n",
    "   # test_acc = f1_score(new_classifier.predict(X_test), Y_test)\n",
    "    test_acc = new_classifier.score(X_test, Y_test)\n",
    "\n",
    "    return test_acc, grid_search.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSVMrbf(X_train,Y_train,X_test,Y_test):\n",
    "    #setup SVM\n",
    "    SVM_classifier = svm.SVC(kernel = 'rbf')\n",
    "    C_list = [10**-6, 10**-5, 10**-4, 10**-3, 10**-2, 10**-1] # Different C to try.\n",
    "    params = {'C': C_list}\n",
    "    grid_search = GridSearchCV(SVM_classifier, params, cv=3, return_train_score = 'true', n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    train_acc = (grid_search.cv_results_['mean_train_score']).reshape(-1,1)\n",
    "    draw_heatmap_linear(train_acc, 'train accuracy', C_list)\n",
    "\n",
    "    val_acc = (grid_search.cv_results_['mean_test_score']).reshape(-1,1)\n",
    "    draw_heatmap_linear(val_acc, 'val accuracy', C_list)\n",
    "\n",
    "    new_classifier = svm.SVC(kernel = 'linear', C = grid_search.best_params_['C'])\n",
    "    new_classifier.fit(X_train, Y_train)\n",
    "    #test_acc = f1_score(new_classifier.predict(X_test), Y_test)\n",
    "    test_acc = new_classifier.score(X_test, Y_test)\n",
    "\n",
    "    return test_acc, grid_search.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRandomForest(X_train, Y_train, X_test, Y_test):\n",
    "    D_list = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "    parameters = {'max_depth':D_list}\n",
    "    clf = RandomForestClassifier(criterion=\"entropy\", n_estimators=1024)\n",
    "    grid_search = GridSearchCV(clf, parameters, cv=5, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    #plot heatmaps\n",
    "    train_acc = (grid_search.cv_results_['mean_train_score']).reshape(-1,1)\n",
    "    draw_heatmap_RF(train_acc, 'RF train accuracy', D_list)\n",
    "\n",
    "    val_acc = grid_search.cv_results_['mean_test_score'].reshape(-1,1)\n",
    "    draw_heatmap_RF(val_acc, 'RF val accuracy', D_list)\n",
    "\n",
    "    #predict with best parameter\n",
    "    best_D = grid_search.best_params_['max_depth']\n",
    "    new_clf = RandomForestClassifier(max_depth=best_D, criterion=\"entropy\", n_estimators=10)\n",
    "    new_clf.fit(X_train, Y_train)\n",
    "    #test_acc = f1_score(new_clf.predict(X_test), Y_test)\n",
    "    test_acc = new_clf.score(X_test, Y_test)\n",
    "\n",
    "    return test_acc, best_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDecisionTree(X_train, Y_train, X_test, Y_test):\n",
    "    estimator = tree.DecisionTreeClassifier()\n",
    "    D_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    params = {\n",
    "                  \"max_depth\": D_list,\n",
    "                  \"criterion\": [\"entropy\"]\n",
    "                 }\n",
    "    clf = GridSearchCV(estimator, param_grid=params, return_train_score = 'true', cv=5)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    train_acc = clf.cv_results_['mean_train_score'].reshape(-1,1)\n",
    "    draw_heatmap_linear(train_acc, 'train accuracy', D_list)\n",
    "\n",
    "    val_acc = clf.cv_results_['mean_test_score'].reshape(-1,1)\n",
    "    draw_heatmap_linear(val_acc, 'val accuracy', D_list)\n",
    "        \n",
    "    best_D = clf.best_params_['max_depth']\n",
    "    new_estimator = tree.DecisionTreeClassifier()\n",
    "    params = {\n",
    "                  \"max_depth\": [best_D],\n",
    "                  \"criterion\": [\"entropy\"]\n",
    "                 }\n",
    "    new_estimator.fit(X_train, Y_train)\n",
    "    test_acc = new_estimator.score(X_test, Y_test)\n",
    "    #test_acc = f1_score(new_estimator.predict(X_test), Y_test)\n",
    "    return test_acc, best_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partitions the dataset and runs the models\n",
    "def RunModels(X_shuffled,Y_shuffled):\n",
    "    all_results=[]\n",
    "    \n",
    "    #iterate through 3 partitions\n",
    "    for split_num in [0.8,0.5,0.2]:\n",
    "        RBFSVM_acc = []\n",
    "        LinearSVM_acc = []\n",
    "        LR_acc = []\n",
    "        RF_acc = []\n",
    "        DT_acc = []\n",
    "        \n",
    "        #iterate through 3 trials\n",
    "        for i in range(3):\n",
    "            cutoff = int(split_num*len(X_shuffled))\n",
    "            X_train = X_shuffled[:cutoff] \n",
    "            Y_train = Y_shuffled[:cutoff]\n",
    "            X_test = X_shuffled[cutoff:] \n",
    "            Y_test = Y_shuffled[cutoff:]\n",
    "            #run RBF SVM\n",
    "            test_acc_rbfSVM, best_C_rbfSVM = runSVMrbf(X_train, Y_train, X_test, Y_test)\n",
    "            RBFSVM_acc.append(test_acc_rbfSVM)\n",
    "            \n",
    "            #run Linear SVM\n",
    "            test_acc_linearSVM, best_C_linearSVM = runSVMlinear(X_train, Y_train, X_test, Y_test)\n",
    "            LinearSVM_acc.append(test_acc_linearSVM)\n",
    "\n",
    "            #run Logistic Regression\n",
    "            test_acc_LR, best_C_LR = runLogisticRegression(X_train, Y_train, X_test, Y_test)\n",
    "            LR_acc.append(test_acc_LR)\n",
    "            \n",
    "            #run RF\n",
    "            test_acc_RF, best_D_RF = runRandomForest(X_train, Y_train, X_test, Y_test)\n",
    "            RF_acc.append(test_acc_RF)\n",
    "            \n",
    "            #run DT\n",
    "            test_acc_DT, best_D_DT = runDecisionTree(X_train, Y_train, X_test, Y_test)\n",
    "            DT_acc.append(test_acc_DT)\n",
    "            \n",
    "        #get avg accuracies from 3 trials    \n",
    "        avg_rbf_SVM_acc = sum(RBFSVM_acc)/3\n",
    "        avg_linear_SVM_acc = sum(LinearSVM_acc)/3\n",
    "        avg_LR_acc = sum(LR_acc)/3\n",
    "        avg_RF_acc = sum(RF_acc)/3\n",
    "        avg_DT_acc = sum(DT_acc)/3\n",
    "\n",
    "        all_results.append(avg_rbf_SVM_acc)\n",
    "        all_results.append(avg_linear_SVM_acc)\n",
    "        all_results.append(avg_LR_acc)\n",
    "        all_results.append(avg_RF_acc)\n",
    "        all_results.append(avg_DT_acc)\n",
    "\n",
    "        print('SVM RBF - ','Partition:', split_num, '; avg accuracy:', avg_rbf_SVM_acc)\n",
    "        print('SVM Linear - ','Partition:', split_num, '; avg accuracy:', avg_linear_SVM_acc)\n",
    "        print('LR - ','Partition:', split_num, '; avg accuracy:', avg_LR_acc)\n",
    "        print('RF - ','Partition:', split_num, '; avg accuracy:', avg_RF_acc)\n",
    "        print('DT - ','Partition:', split_num, '; avg accuracy:', avg_DT_acc)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Dataset (Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset.\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "Y = (iris.target > 1.5).reshape(-1,1)\n",
    "X_and_Y = np.hstack((X, Y))     \n",
    "np.random.seed(1)               \n",
    "np.random.shuffle(X_and_Y)      \n",
    "\n",
    "X_shuffled_iris = X_and_Y[:,:4]\n",
    "Y_shuffled_iris = X_and_Y[:,4]\n",
    "print(X_shuffled_iris.shape, Y_shuffled_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(0.8*len(X))\n",
    "\n",
    "X_train = X_shuffled_iris[:cutoff] \n",
    "Y_train = Y_shuffled_iris[:cutoff] \n",
    "X_test = X_shuffled_iris[cutoff:] \n",
    "Y_test = Y_shuffled_iris[cutoff:]  \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_results = RunModels(X_shuffled_iris, Y_shuffled_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Dataset (letter recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterToLabel(val):\n",
    "    first_half_alphabet = [b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I', b'J', b'K', b'L', b'M']\n",
    "    if (val in first_half_alphabet):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load letter dataset\n",
    "letter_data = np.loadtxt('./letter-recognition.data', delimiter=',', converters={0:letterToLabel})\n",
    "X_and_Y = letter_data\n",
    "np.random.seed(1) \n",
    "np.random.shuffle(X_and_Y)\n",
    "X_shuffled_letters = X_and_Y[:5000,1:17]\n",
    "Y_shuffled_letters = X_and_Y[:5000,0]\n",
    "print(X_shuffled_letters.shape, Y_shuffled_letters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_results = RunModels(X_shuffled_letters,Y_shuffled_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(letter_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Dataset (Adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load adult dataset\n",
    "adult_data = pd.read_csv('./adult.data', header=None, names=['age','workclass','fnlwgt','education','education-num',\n",
    "                                                'marital-status','occupation','relationship','race','sex',\n",
    "                                                'capital-gain','capital-loss','hours-per-week','native-country',\n",
    "                                                'above-50k'], na_values='?', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_mask = adult_data.applymap(np.isreal).all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "onehot = preprocessing.OneHotEncoder(categorical_features=bool_mask)\n",
    "for column in adult_data:\n",
    "    if(adult_data[column].dtype!=int):\n",
    "        adult_data[column] = le.fit_transform(adult_data[column])\n",
    "adult_data = onehot.fit_transform(adult_data).toarray()\n",
    "adult_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_and_Y = adult_data[np.random.choice(32561, 2000), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "np.random.shuffle(X_and_Y)\n",
    "X_shuffled_adult=X_and_Y[:, :-1]\n",
    "Y_shuffled_adult=X_and_Y[:, -1]\n",
    "print(X_shuffled_adult.shape, Y_shuffled_adult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_results = RunModels(X_shuffled_adult,Y_shuffled_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adult_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
